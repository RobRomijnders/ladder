{
  "name": "Ladder",
  "tagline": "LADDER network after Harri Valpola",
  "body": "## Ladder network\r\nThis post implements the Ladder network, proposed in [this](https://arxiv.org/pdf/1411.7783.pdf) and [this](http://arxiv.org/pdf/1507.02672v2.pdf) paper for Tensorflow. The ladder network allows for semi-supervised learning. In this setting, the network learns from both labelled and unlabelled data. For example, the ladder network achieves only 0.0106 test error on MNIST using 100 labelled examples (ten labelled examples per class).\r\n\r\n## Outline\r\n_This section aims to outline the network. The [paper](http://arxiv.org/pdf/1507.02672v2.pdf) describes further details._\r\nA ladder network combines supervised and unsupervised learning. Supervised learning takes form as feedforward neural nets, convolutional nets and recurrent nets. Unsupervised learning takes form as auto-encoding the distributed representations.\r\nSupervised and unsupervised learning contrast in their preservation of detail. Supervised learning serves one task at hand. It discards the details in the input that do not contribute. Unsupervised learning preserves a range of details and concepts in order to reconstruct it at the decoder. Every stage of the ladder combines the two: One objective function monitors the reconstruction of the distributed representation at the decoder side. Another objective (at the topmost level) monitors the classification performance of the encoder network. The reconstruction-objectives require no labels. Yet they involve the entire network. Therefore, unlabelled data can train the network too.\r\n\r\nAnother way to understand ladder networks is via this analogy:\r\nHumans do semi-supervised learning too. Say we'd train your friend to classify oak trees from maple trees. We need maybe five or six examples so he can classify them with reasonable accuracy. Yet we'd need thousands of examples for a computer to achieve similar accuracy. Why is this? Well, he has seen many trees throughout his live. He understands the general structure of a tree. We only need few examples to add the fine details that discriminate a maple from an oak tree.\r\nThe interplay of encoder and decoder follow this analogy too. The unsupervised/auto-encoding part of the ladder network teaches the network a gross understanding of concepts in the data. It needs to do this to achieve reconstruction. The supervised/encoder part of the ladder network teaches the network the fine-grained details that discriminate one class from the other. \r\nIn other words _the unsupervised objective preserves a range of features and with the few labelled samples the network decides which features support classification_\r\n[Do you like more intuitive explanations, images and videos? I'd recommend Harri Valopola's talk at this symposium.](https://www.youtube.com/watch?v=ZlyqNiPFu2s)\r\n\r\n## Code\r\nA quick Google-search brings us two implementations in Tensorflow\r\n\r\n  * By [rinuboney](https://github.com/rinuboney/ladder)\r\n  * By [tarvaina](https://github.com/tarvaina/tensorflow-ladder)\r\nI decided to continue on rinuboney's work. It works top-down in one file and is an easy read.\r\n[Harri Valpola](https://www.youtube.com/watch?v=ZlyqNiPFu2s) proposes the ladder network in his talk as a general framework. It applies to any neural network that can encode and decode representations. The repo by rinuboney implements the basic MLP version. This post continues with his code and implements it for convolutional neural networks. \r\n_(I consider to implement a recurrent ladder network too. Email me at romijndersrob@gmail.com if you'd be interested in that)_\r\n\r\n## Results\r\nThe ladder network applies to many neural networks where you'd like semi-supervised learning. The results and visualizations will depend on your application. For the moment, I made it work on MNIST\r\n![18](https://github.com/RobRomijnders/ladder/blob/master/im/figure_18.png?raw=true)\r\n![19](https://github.com/RobRomijnders/ladder/blob/master/im/figure_19.png?raw=true)\r\n![21](https://github.com/RobRomijnders/ladder/blob/master/im/figure_21.png?raw=true)\r\n\r\nAs always, I am curious to any comments and questions. Reach me at romijndersrob@gmail.com",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}